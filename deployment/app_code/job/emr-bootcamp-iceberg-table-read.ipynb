{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bdd2ab-206a-431f-9ca4-5380fe56b1e2",
   "metadata": {},
   "source": [
    "# 0. Connect to EMR Cluster with Analyst Runtime Role\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "In this section, we connect to EMR cluster and create Spark session with *data analyst* EMR runtime role, which is designed as a Lake Formation database and table reader. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672c209-4b83-48ac-b34c-2be1c3910097",
   "metadata": {},
   "source": [
    "## 0.1 Install and load sagemaker studio extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall sagemaker-studio-analytics-extension -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82cd72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install sagemaker-studio-analytics-extension==0.0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aba589-9328-4dc2-b305-2643f65a652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sagemaker_studio_analytics_extension.magics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45b58d-7d08-4d9c-813f-d6c392744ac6",
   "metadata": {},
   "source": [
    "## 0.2 Get EMR cluster ID and EMR runtime role\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> In case the following `sm_analytics emr connect` cell fails with the message:\n",
    " <b>   Warning: The Spark session does not have enough YARN resources to start.</b> \n",
    "Terminate unneeded Livy sessions to free the cluster resources.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6856716-be41-4ead-9f66-4f34668fcb04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "source ~/.bash_profile\n",
    "EMR_CLUSTER_ID=$(aws emr list-clusters --active  --query 'Clusters[?contains(Name,`emr-bootcamp-runtime-role-lf`)].Id' --output text)\n",
    "echo \"ACCOUNT_ID:   $ACCOUNTID\"\n",
    "echo \"REGION:       $REGION\"\n",
    "echo \"CLUSTER_ID:   $EMR_CLUSTER_ID\"\n",
    "echo \"IAM_ARN:      $ANALYST_ROLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba196843-9f1d-4649-9d10-c51d9b84ccd2",
   "metadata": {},
   "source": [
    "## 0.3 Connect to EMR cluster with runtime role and create Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20771e68-227c-4111-a99d-3eb6f886e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sm_analytics emr connect \\\n",
    "--cluster-id <CLUSTER_ID> \\\n",
    "--auth-type Basic_Access \\\n",
    "--emr-execution-role-arn <ANALYST_ROLE_ARN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca8884-e9ea-4408-9cbf-f81c52d66fb2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Before execute the %%configure, ensure all the placeholders are replaced\n",
    "</div>\n",
    "\n",
    "* Replace `<ACCOUNT_ID>` with your AWS accout ID\n",
    "* Replace `<REGION>` with your region, e.g. `us-east-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd308fbc-7ef0-4252-83a1-adea4a1ac60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "\"conf\":{\n",
    "         \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,com.amazonaws.emr.recordserver.connector.spark.sql.RecordServerSQLExtension\",\n",
    "         \"spark.sql.catalog.iceberg_catalog\":\"org.apache.iceberg.spark.SparkCatalog\",\n",
    "         \"spark.sql.catalog.iceberg_catalog.warehouse\":\"s3://lf-datalake-<ACCOUNT_ID>-us-east-1/\",\n",
    "         \"spark.sql.catalog.iceberg_catalog.catalog-impl\":\"org.apache.iceberg.aws.glue.GlueCatalog\", \n",
    "         \"spark.sql.catalog.iceberg_catalog.io-impl\":\"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "         \"spark.sql.catalog.iceberg_catalog.glue.account-id\":\"<ACCOUNT_ID>\",\n",
    "         \"spark.sql.catalog.iceberg_catalog.glue.id\":\"<ACCOUNT_ID>\",\n",
    "         \"spark.sql.catalog.iceberg_catalog.client.assume-role.region\":\"<REGION>\",\n",
    "         \"spark.sql.catalog.iceberg_catalog.lf.managed\":\"true\",\n",
    "    \n",
    "         \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "         \"spark.dynamicAllocation.minExecutors\": \"3\",\n",
    "         \"spark.dynamicAllocation.maxExecutors\": \"5\"\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1aedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col,lit, current_timestamp,unix_timestamp, min, when, desc, split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde4c2d-1a61-4074-a7f5-d6acfb3048dc",
   "metadata": {},
   "source": [
    "# 1. Config Parameters for Iceberg Data Lake \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "In this section, we config the parameters for source data and iceberg database and table that will be created\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410bb4b7-e7d8-49bc-ad9d-7702ae591609",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Replace the following paramters\n",
    "</div>\n",
    "\n",
    "* Replace `ACCOUNT-ID` with your account ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8f85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LF_S3_BUCKET_NAME = \"lf-datalake-<ACCOUNT-ID>-us-east-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29436d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "\n",
    "# source data variables\n",
    "SRC_DB_NAME = \"tpcparquet\"\n",
    "SRC_TABLE_NAME = \"dl_tpc_customer\"\n",
    "\n",
    "# Iceberg variables\n",
    "ICEBERG_CATALOG = \"iceberg_catalog\"\n",
    "ICEBERG_DATABASE = f\"emr_bootcamp_iceberg_db_{VERSION}\"\n",
    "ICEBERG_DATABASE_LOCATION = f\"s3://{LF_S3_BUCKET_NAME}/{ICEBERG_DATABASE}\"\n",
    "ICEBERG_TABLE_NAME = f\"emr_bootcamp_iceberg_sql_{SRC_TABLE_NAME}_{VERSION}\"\n",
    "ICEBERG_TABLE_LOCATION = f\"{ICEBERG_DATABASE_LOCATION}/{ICEBERG_TABLE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2806e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sparkmagic SQL configs\n",
    "\n",
    "spark.conf.set('iceberg_catalog', ICEBERG_CATALOG)\n",
    "spark.conf.set('iceberg_db', ICEBERG_DATABASE)\n",
    "spark.conf.set('iceberg_table_name', ICEBERG_TABLE_NAME)\n",
    "\n",
    "print (\"iceberg_catalog:              \"+ICEBERG_CATALOG)\n",
    "print (\"iceberg_db:                   \"+ICEBERG_DATABASE)\n",
    "print (\"iceberg_table_name:           \"+ICEBERG_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a6fbe-3e5d-4699-be16-cfe33798074b",
   "metadata": {},
   "source": [
    "# 2. Query Iceberg table\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "In this section, we query iceberg with data analyst EMR runtime role to see if three PII columns: c_customer_id, c_email_address, and c_last_name have been excluded\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> In case you see the timeout error \"RecordServerException: Could not fetch metadata after maximum number of retries\", run the following cells again. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340e6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- the full table contains 7 columns\n",
    "\n",
    "DESCRIBE TABLE ${iceberg_catalog}.${iceberg_db}.${iceberg_table_name} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a1151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- the analyst role only can see 4 columns\n",
    "\n",
    "SELECT *  \n",
    "FROM ${iceberg_catalog}.${iceberg_db}.${iceberg_table_name}\n",
    "WHERE \n",
    "    c_birth_country = 'INDIA'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
